# ğŸ¤– CLAUDE.md - Best Practices de DÃ©veloppement

Ce document dÃ©finit les **standards de dÃ©veloppement** et **best practices** pour le projet Athle Tracker. Il est destinÃ© Ã  Ãªtre utilisÃ© par Claude Code et les dÃ©veloppeurs humains.

---

## ğŸ“‹ Table des MatiÃ¨res

1. [Architecture & Design Patterns](#-architecture--design-patterns)
2. [Standards de Code](#-standards-de-code)
3. [Base de DonnÃ©es](#-base-de-donnÃ©es)
4. [Tests](#-tests)
5. [SÃ©curitÃ©](#-sÃ©curitÃ©)
6. [Performance](#-performance)
7. [Documentation](#-documentation)
8. [Git Workflow](#-git-workflow)
9. [Intelligence de Migration](#-intelligence-de-migration)

---

## ğŸ—ï¸ Architecture & Design Patterns

### Clean Architecture

Le projet suit strictement la **Clean Architecture** :

```
core/           â† Business Logic (ne dÃ©pend de rien)
â†‘
infrastructure/ â† ImplÃ©mentations techniques
â†‘
presentation/   â† UI (Streamlit)
```

**RÃ¨gles d'or :**

1. âœ… **Core ne dÃ©pend jamais de Infrastructure ou Presentation**
2. âœ… **Infrastructure implÃ©mente les interfaces dÃ©finies dans Core**
3. âœ… **Presentation utilise Infrastructure via Dependency Injection**
4. âŒ **Jamais d'import direct de SQLAlchemy dans Core**
5. âŒ **Jamais d'import de Streamlit en dehors de Presentation**

### Repository Pattern

Toutes les opÃ©rations de donnÃ©es passent par des **repositories** :

```python
# âœ… BON : Interface dans core/interfaces/
class UserRepository(ABC):
    @abstractmethod
    def get_by_email(self, email: str) -> Optional[User]:
        pass

# âœ… BON : ImplÃ©mentation dans infrastructure/
class SQLAlchemyUserRepository(UserRepository):
    def get_by_email(self, email: str) -> Optional[User]:
        return self.session.query(User).filter(User.email == email).first()

# âŒ MAUVAIS : AccÃ¨s direct Ã  la DB dans Use Case
user = session.query(User).filter(User.email == email).first()
```

### Use Cases Pattern

Chaque **action mÃ©tier** = 1 Use Case :

```python
# âœ… BON : Use Case dÃ©diÃ©
class ScrapeRankingsUseCase:
    def __init__(self, session: Session) -> None:
        self.ranking_repo = SQLAlchemyRankingRepository(session)
        self.alert_repo = SQLAlchemyAlertRepository(session)

    async def execute(self, epreuve_code: int, sexe: str) -> dict:
        # Logique mÃ©tier ici
        pass

# âŒ MAUVAIS : Logique mÃ©tier dans le controller
def scrape_button_clicked():
    # 50 lignes de logique...
```

---

## ğŸ“ Standards de Code

### Type Hints OBLIGATOIRES

```python
# âœ… BON
def get_rankings(epreuve_code: int, sexe: str) -> List[RankingDTO]:
    pass

# âŒ MAUVAIS
def get_rankings(epreuve_code, sexe):
    pass
```

### Docstrings pour Fonctions Publiques

```python
# âœ… BON
def scrape_rankings(epreuve_code: int) -> List[Dict]:
    """
    Scrape rankings from athle.fr.

    Args:
        epreuve_code: Competition code (e.g., 670 for javelin)

    Returns:
        List of ranking dictionaries

    Raises:
        ScrapingError: If scraping fails after retries
    """
    pass
```

### Fonctions Courtes (<50 lignes)

```python
# âœ… BON : Fonction courte et focalisÃ©e
def parse_performance(performance_str: str) -> tuple[str, float]:
    """Parse performance string to clean value and numeric."""
    clean = re.sub(r"\s*\([^)]*\)", "", performance_str).strip()
    match = re.match(r"(\d+)m(\d+)", clean)
    if match:
        meters = int(match.group(1))
        centimeters = int(match.group(2))
        return clean, meters + (centimeters / 100.0)
    return clean, 0.0

# âŒ MAUVAIS : Fonction trop longue (>100 lignes)
def scrape_and_process_everything():
    # 150 lignes...
```

### DRY (Don't Repeat Yourself)

```python
# âœ… BON : RÃ©utilisation
def format_datetime(dt: datetime) -> str:
    return dt.strftime("%d/%m/%Y %H:%M")

# Usage
st.write(format_datetime(ranking.created_at))
st.write(format_datetime(alert.created_at))

# âŒ MAUVAIS : Duplication
st.write(ranking.created_at.strftime("%d/%m/%Y %H:%M"))
st.write(alert.created_at.strftime("%d/%m/%Y %H:%M"))
```

### Error Handling Robuste

```python
# âœ… BON : Try/except avec logging
try:
    result = await scraper.scrape_rankings(code, sexe)
except ScrapingError as e:
    logger.error(f"Scraping failed: {e}")
    return {"success": False, "error": str(e)}
except Exception as e:
    logger.error(f"Unexpected error: {e}")
    raise

# âŒ MAUVAIS : Silence les erreurs
try:
    result = scraper.scrape_rankings(code, sexe)
except:
    pass
```

---

## ğŸ—„ï¸ Base de DonnÃ©es

### Migrations

Toute modification du schÃ©ma = **migration Alembic** :

```bash
# GÃ©nÃ©rer une migration
alembic revision --autogenerate -m "Add column X to table Y"

# Appliquer
alembic upgrade head

# Rollback
alembic downgrade -1
```

### Indexes

Toujours crÃ©er des **indexes** pour :
- Foreign keys
- Colonnes utilisÃ©es dans WHERE
- Colonnes utilisÃ©es dans ORDER BY

```python
# âœ… BON : Indexes dÃ©finis
__table_args__ = (
    Index("idx_ranking_date_epreuve_sexe", "snapshot_date", "epreuve_code", "sexe"),
)

# âŒ MAUVAIS : Pas d'index sur colonnes frÃ©quentes
```

### Transactions

Utiliser **context managers** :

```python
# âœ… BON
with get_db_session() as session:
    user_repo = SQLAlchemyUserRepository(session)
    user = user_repo.create(user_data)
    # Auto-commit si succÃ¨s, rollback si erreur

# âŒ MAUVAIS : Session manuelle non fermÃ©e
session = SessionLocal()
user = session.query(User).first()
# Oubli de session.close()
```

---

## ğŸ§ª Tests

### Coverage >80% OBLIGATOIRE

```bash
pytest --cov=src --cov-report=html --cov-fail-under=80
```

### Tests Unitaires (Use Cases)

```python
# tests/unit/test_scrape_rankings.py
@pytest.mark.unit
def test_scrape_rankings_success(mock_session):
    """Test successful scraping."""
    use_case = ScrapeRankingsUseCase(mock_session)
    result = await use_case.execute(670, "M")

    assert result["success"] is True
    assert result["rankings_count"] > 0
```

### Tests d'IntÃ©gration (Scraper)

```python
# tests/integration/test_athle_scraper.py
@pytest.mark.integration
@pytest.mark.slow
async def test_scrape_real_data():
    """Test scraping real athle.fr data."""
    scraper = AthleScraper()
    rankings = await scraper.scrape_rankings(670, "M")

    assert len(rankings) > 0
    assert rankings[0]["rank"] == 1
```

### Fixtures RÃ©utilisables

```python
# tests/fixtures/database.py
@pytest.fixture
def test_db():
    """Create test database."""
    engine = create_engine("sqlite:///:memory:")
    Base.metadata.create_all(engine)
    yield engine
    Base.metadata.drop_all(engine)
```

---

## ğŸ”’ SÃ©curitÃ©

### Passwords

```python
# âœ… BON : Toujours hasher
password_hash = bcrypt.hash(plain_password)

# âŒ MAUVAIS : Stocker en clair
user.password = plain_password
```

### SQL Injection

```python
# âœ… BON : Utiliser l'ORM
user = session.query(User).filter(User.email == email).first()

# âŒ MAUVAIS : SQL brut
session.execute(f"SELECT * FROM users WHERE email = '{email}'")
```

### Secrets

```python
# âœ… BON : Variables d'environnement
SECRET_KEY = os.getenv("SECRET_KEY")

# âŒ MAUVAIS : HardcodÃ©
SECRET_KEY = "super-secret-123"
```

---

## âš¡ Performance

### Bulk Operations

```python
# âœ… BON : Bulk insert
rankings = [Ranking(**data) for data in rankings_data]
session.bulk_save_objects(rankings)

# âŒ MAUVAIS : Boucle
for data in rankings_data:
    ranking = Ranking(**data)
    session.add(ranking)
    session.commit()  # Commit Ã  chaque itÃ©ration !
```

### N+1 Queries

```python
# âœ… BON : Eager loading
rankings = session.query(Ranking).options(
    joinedload(Ranking.athlete),
    joinedload(Ranking.epreuve)
).all()

# âŒ MAUVAIS : N+1
rankings = session.query(Ranking).all()
for r in rankings:
    print(r.athlete.name)  # Query pour chaque athlete !
```

### Caching

```python
# âœ… BON : Cache les requÃªtes lourdes
@st.cache_data(ttl=3600)
def get_rankings(epreuve_code: int, sexe: str) -> List[Dict]:
    # Calcul coÃ»teux
    return rankings
```

---

## ğŸ“š Documentation

### README.md

- Vue d'ensemble du projet
- Installation
- Configuration
- Utilisation

### CLAUDE.md (ce fichier)

- Best practices
- Standards de dÃ©veloppement
- Conventions

### Docstrings

```python
# âœ… BON : Docstring complÃ¨te
def scrape_rankings(
    epreuve_code: int,
    sexe: str,
    annee: int = 2026,
) -> List[Dict[str, Any]]:
    """
    Scrape rankings from athle.fr with retry logic.

    Args:
        epreuve_code: Competition code (e.g., 670 for Javelin)
        sexe: Gender (M or F)
        annee: Year (default 2026)

    Returns:
        List of ranking dictionaries with keys:
        - rank (int)
        - athlete_id (str)
        - name (str)
        - performance (str)
        - club (str)

    Raises:
        ScrapingError: If scraping fails after all retries

    Example:
        >>> rankings = await scraper.scrape_rankings(670, "M")
        >>> print(rankings[0])
        {'rank': 1, 'name': 'John Doe', ...}
    """
```

---

## ğŸ”€ Git Workflow

### Branches

- `main` : Production-ready
- `develop` : Development
- `feature/nom-feature` : Nouvelles features
- `fix/nom-bug` : Bug fixes

### Commits

Format : `type(scope): message`

```bash
# âœ… BON
git commit -m "feat(scraper): add retry with exponential backoff"
git commit -m "fix(auth): prevent SQL injection in login"
git commit -m "docs(readme): update installation instructions"

# âŒ MAUVAIS
git commit -m "update"
git commit -m "fix bug"
```

Types :
- `feat` : Nouvelle feature
- `fix` : Bug fix
- `docs` : Documentation
- `refactor` : Refactoring
- `test` : Tests
- `chore` : Maintenance

---

## ğŸš€ Intelligence de Migration

### Triggers CRITIQUES (Proposer migration AVANT implÃ©mentation)

Si le user demande :
- ğŸ“± Application mobile
- ğŸŒ API publique externe
- ğŸ‘¥ >100 users concurrent
- ğŸ¢ SaaS multi-tenant

**Action :**
1. âš ï¸ **STOP** : Ne pas implÃ©menter
2. ğŸ’¡ Proposer migration vers **FastAPI + React**
3. ğŸ“Š Estimer effort (10-12 jours)
4. âœ… Attendre validation user

### Triggers RECOMMANDÃ‰S (Signaler APRÃˆS implÃ©mentation)

Si le projet atteint :
- ğŸ… >4 Ã©preuves actives
- ğŸ¨ UI trÃ¨s customisÃ©e
- âš¡ Temps rÃ©el / WebSockets nÃ©cessaire
- ğŸŒ Performance dÃ©gradÃ©e (>3s page load)

**Action :**
1. âœ… ImplÃ©menter quand mÃªme
2. ğŸ’¡ Mentionner dans le commit/PR
3. ğŸ“ Documenter la limitation

---

## ğŸ¯ Checklist Avant Commit

Avant chaque commit, vÃ©rifier :

- [ ] âœ… Code formatÃ© avec Black
- [ ] âœ… Pas d'erreurs Ruff
- [ ] âœ… Pas d'erreurs Mypy
- [ ] âœ… Tests passent (pytest)
- [ ] âœ… Coverage >80%
- [ ] âœ… Docstrings Ã  jour
- [ ] âœ… Type hints prÃ©sents
- [ ] âœ… Logs appropriÃ©s
- [ ] âœ… Pas de secrets hardcodÃ©s
- [ ] âœ… README Ã  jour si nÃ©cessaire

---

## ğŸ“ Questions ?

Si doute sur :
- Architecture â†’ Relire Clean Architecture
- Standards â†’ Relire ce fichier
- Tests â†’ Voir tests existants
- SÃ©curitÃ© â†’ En parler AVANT d'implÃ©menter

---

**DerniÃ¨re mise Ã  jour : 2025-11-02**
**Version : 1.0.0**
